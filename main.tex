\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath,setspace,geometry}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage[shortlabels]{enumitem}
\usepackage{rotating}
\usepackage{pdflscape}
\usepackage{graphicx}
\usepackage{bbm}
\usepackage[dvipsnames]{xcolor}
\usepackage{hyperref}
\hypersetup{colorlinks=true, linkcolor= BrickRed, citecolor = BrickRed, filecolor = BrickRed, urlcolor = BrickRed, hypertexnames = true}
\usepackage[]{natbib} 
\bibpunct[:]{(}{)}{,}{a}{}{,}
\geometry{left = 1.0in,right = 1.0in,top = 1.0in,bottom = 1.0in}
\usepackage[english]{babel}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{pdfpages}
\usepackage{threeparttable}
\usepackage{lscape}
\usepackage{bm}

\renewcommand*{\epsilon}{\varepsilon}

\usepackage{setspace}
\setstretch{1.2}

\title{An MPEC Estimator for Sequential Search model}
\author{Shinji Koiso\thanks{koiso-shinji970@g.ecc.u-tokyo.ac.jp, Department of Economics, University of Tokyo}, Suguru Otani\thanks{suguru.otani@e.u-tokyo.ac.jp, Market Design Center, University of Tokyo\\Declarations of interest: none}}
\date{December 2023}

\begin{document}

\maketitle

\begin{abstract}
\noindent
%150 words:
In this paper, we propose a constrained maximum likelihood estimator for sequential search models, by formulating the estimation as an MPEC (Mathematical Programming with Equilibrium Constraints) problem. 
Our approach improves the numerical accuracy and avoids introducing ad hoc components and estimation and approximation errors regarding equilibrium conditions. 
Monte Carlo simulations confirm that the proposed estimator reduces bias and Root-Means-Squared-Error (RMSE) of the estimator, \textcolor{blue}{especially when XXX.}
\\
%100 words AER
\textbf{Keywords}: XX \\
\textbf{JEL code}: XX
\end{abstract}

\section{Introduction}

Consumer search process to gather information about possible options is prevalent in the actual choice behavior.
The search process has increasingly become observable to researchers. 
For example, browsing data allows the researcher to observe which options an agent inspects before making a choice. 
The increased availability of consumer search data has led researchers to estimate structural models of consumer search behavior, summarized in \cite{ursu2023sequential}. 
The current benchmark model nests the inner loop step to solve implicit functions regarding reserved prices of searching decisions as a fixed point problem, which is known to be computationally burdensome.

To overcome the problem, we propose a new estimator based on the mathematical program
with equilibrium constraints (MPEC) approach advocated by \cite{su2012constrained}. 
MPEC is a constrained optimization problem whose constraint structure contains the equilibrium constraints.
The main advantage of MPEC is that MPEC does not need to solve the fixed point problem iteratively, which is well known in the demand estimation \citep{dube2012improving}, dynamic programming \citep{su2012constrained,egesdal2015estimating}, and misclassification model \citep{lu2014mpec}.
Also, it does not incorporate approximation and estimation errors of equilibrium constraints induced by the other approaches.
\textcolor{blue}{
[TBA] Based on Monte Carlo simulations, MPEC shows comparable or better performance for the sequential search model relative to the nested fixed point approaches and the advantage carries over. 
The main drawbacks of MPEC are the use of PC memory and computational time.
We conclude that MPEC is the best alternative among the current approaches to find a benchmark estimate before going to a more complicated model when the approximation and estimation errors and an ad hoc look-up table are unknown to researchers. 
}


\section{Weitzman's sequential search model}

\subsection{The Weitzman (1979) Framework}
We construct the sequential search model based on \cite{weitzman1979optimal}.
See the detail in the unified survey of \cite{ursu2023sequential} and \cite{honka2019empirical}. 
A decision maker $i$ faces a set of $\mathcal{J}=\{1,\cdots,J\}$ boxes and box $j$ gives a potential reward $u_{ij}\in \mathbb{R}$ independently drawn from a known
distribution $F_{ij}(u)$.
Opening box $j$ takes cost $c_{ij}\in \mathbb{R}^{++}$. 
An outside option is denoted as $j = 0$ with a known reward $u_{i0}$ is available at no cost.
The decision maker
opens boxes via sequential search steps and her goal is to maximize her expected reward net of total costs.

Suppose that the decision maker has opened a set \(S_{i}\) of boxes,
which revealed a maximum reward value of \(u_{i}^{*}=\max _{j \in S_{i} \cup 0} u_{i j}\), and \(\bar{S}_{i}\) unopened boxes can still be
opened. 
Her dynamic programming problem choosing to stop opening boxes, in which case she
gets payoff \(u_{i}^{*}\), or to continue opening boxes is described
by the following Bellman equation:
\begin{align}
    V\left(\bar{S}_{i}, u_{i}^{*}\right)=\max \left\{u_{i}^{*}, \max _{j \in \bar{S}_{i}}\left\{-c_{i j}+W_{j}\left(\bar{S}_{i}, u_{i}^{*}\right)\right\}\right\}
\end{align}
where \(W_{j}\left(\bar{S}_{i}, u_{i}^{*}\right)\) is the expected value of continuing to open boxes and is
defined as
\begin{align}
    W_{j}\left(\bar{S}_{i}, u_{i}^{*}\right)=V\left(\bar{S}_{i} \backslash j, u_{i}^{*}\right) \int_{-\infty}^{u_{i}^{*}} d F_{i j}(u)+\int_{u_{i}^{*}}^{\infty} V\left(\bar{S}_{i} \backslash j, u\right) d F_{i j}(u).
\end{align}
Also, the reservation utility of a product \(z_{i j}\) is the utility level defined as 
\begin{align}
    \int_{z_{i j}}^{\infty}\left(u_{i j}-z_{i j}\right) d F_{i j}\left(u_{i j}\right)=c_{i j}.
\end{align}

A set of optimal decision rules, developed by
\cite{weitzman1979optimal}, is used to characterize consumers' optimal search and choice strategies. 
The rules are as follows:
\begin{enumerate}
    \item Consumers know the true distribution(s) \(F_{i j}(u)\).
    \item Search fully reveals the utility associated with product \(j\).
    \item For each consumer \(i, u_{i j}\) is independently (across \(j\) ) drawn from \(F_{i j}(u)\).
\end{enumerate}
Then, the optimal search and choice decision
rules are expressed as follows:
\begin{enumerate}
    \item Selection Rule: The consumer searches in decreasing order of reservation utilities.
    \item Stopping Rule: Search terminates when the maximum observed utility exceeds the reservation utility of any unsearched product.
    \item Choice Rule: Once the consumer stops searching, she chooses the product with the highest observed utility among all searched options.
\end{enumerate}

\subsection{Parametrizations for Empirical Work}

Empirical economists often assume consumer $i$'s utility from product $j$ has two additively separable components:
\begin{align}
    u_{i j} & =\delta_{i j}+\varepsilon_{i j}  =\left(\xi_{i j}+\mu_{i j}\right)+\varepsilon_{i j},\\
    \quad \quad \varepsilon_{i j}&\sim_{i.i.d} N(0,\sigma_{\mu}),\quad \mu_{i j} \sim_{i.i.d} N(0,\sigma_{\varepsilon})\nonumber
\end{align}
where \(\delta_{i j}\) is utility which is known by the consumer prior to search ("pre-search
utility" in the following) and \(\varepsilon_{i j}\) is utility that is only known by the consumer
after search ("post-search taste shock" in the following). 
We assume that the pre-search utility
\(\delta_{i j}\) consists of a component \(\xi_{i j}\) that can be observed by the researcher and a pre-search taste shock \(\mu_{i j}\) that
cannot be observed by the researcher. 
According to \cite{ursu2023sequential}, we need to further normalize their variance by setting $\sigma_{\mu}= \sigma_{\varepsilon} =1$. 

Under the assumption of normally distributed post-search taste shocks, we can derive the following
expression for the reservation utility:
\begin{align}
    z_{i j}=\delta_{i j}+m\left(c_{i j}\right)=\xi_{i j}+\mu_{i j}+m\left(c_{i j}\right) 
\end{align}
where \(m\left(c_{i j} \right)\) is the implicit function that solves the following equation (see \cite{kim2010online}):
\begin{align}
    c_{i j}=\phi(m)+m \times[\Phi(m)-1] \label{eq:equilibrium_constraint}
\end{align}
with \(\phi\) and \(\Phi\) denoting the standard normal pdf and cdf, respectively. \cite{weitzman1979optimal} shows the existence and uniqueness of the solution of \eqref{eq:equilibrium_constraint}.

There are four methods to solve \eqref{eq:equilibrium_constraint}. 
A first approach, proposed by \cite{kim2010online}, is pre-computing the mapping between $m$ and $c$ and saving it in a look-up table.
A second approach proposed by \cite{jiang2021consumer} utilizes Newton's method to compute reservation utilities by successively better approximations to the root
of a function 
\begin{align*}
    q(m)=(1-\Phi(m))\left(\frac{\phi(m)}{1-\Phi(m)}-m\right)-c=0.
\end{align*}
A third approach proposed by \cite{elberg2019dynamic} is to use a contraction mapping of
\begin{align*}
    \Gamma(m)=-c+\phi(m)+m \times \Phi(m).
\end{align*}
A fourth approach proposed by \cite{morozov2023measuring} is to directly estimate $m(c_{ij})$.

\cite{ursu2023sequential} mention that (1) the first method introduces error from using linear interpolations for search cost
values that are not equal to grid-point values, (2) the second and third methods avoid any error from using linear interpolation but involve iterations of finding $m$ and defining a convergence threshold which can result in numerical errors when the threshold is too loose, (3) the fourth approach involves estimation error on $m(c_{ij})$. 
In practice, both methods appear to converge quickly and allow researchers to set tight convergence thresholds thus avoiding numerical problems \citep{ursu2023sequential}. 
Similar problems on demand estimation are discussed and resolved by MPEC introduced next \citep{dube2012improving}. 



\section{An MPEC estimator for the sequential search model}
As the fifth method, we propose a novel and simple estimator for the sequential search model by utilizing the Mathematical Programming with Equilibrium Constraints (MPEC) procedure advocated by \cite{su2012constrained}. 
Our setting is similar to \cite{su2012constrained} in which the likelihood function function with equilibrium constraints is constructed. 
MPEC estimator avoids iterative computations to find the fixed point by evaluating the equilibrium equations as constraints.

Define $\theta$ as a set of parameters.
Given the optimal decision rules and reservation utility formula, an MPEC estimator solves the following constrained problem:
\begin{align}
    \max_{\theta}& \sum_{i\in \mathcal{N}} \log L_{i}(\theta,(z_{ij})_{j\in \mathcal{J}},(u_{ij})_{j\in \mathcal{J}})\nonumber\\
    \text{s.t.}\quad u_{i j} & =\xi_{i j}+\mu_{i j}+\varepsilon_{i j}\label{eq:mpec_formula}\\
    z_{i j}&=\xi_{i j}+\mu_{i j}+m\left(c_{i j}\right) \nonumber\\
    c_{i j}&=\phi(m)+m \times[\Phi(m)-1] \nonumber
\end{align}
where individual likelihood $L_{i}(\theta,(z_{ij})_{j\in \mathcal{J}},(u_{ij})_{j\in \mathcal{J}})$ is derived as
\begin{align*}
    L_{i}(\theta,(z_{ij}(\theta))_{j\in \mathcal{J}}) &= \Pr (\underbrace{z_{ih} \geq \max_{k \in \mathcal{J}\setminus \{1,\cdots,h\}} z_{ik} \: \forall h \in S_i}_{\text{selection rule}}\\
    & \cap \underbrace{z_{ih} \geq \max_{k = 1}^{h-1} u_{ik} \: \forall h \in S_i \cap \max_{h \in S_i \cup \{0\}} u_{ih} \geq \max_{l \in \bar{S}_i} z_{il} }_{\text{stopping rule}}\\
    & \cap \underbrace{u_{iy_i} \geq \max_{h \in S_i \cup \{0\}} u_{ih} }_{\text{choice rule}}).
\end{align*}

A remarkable advantage of MPEC is that it does not need an ad hoc look-up table which is unknown to researchers and does not incorporate approximation and estimation error of equilibrium constraints \eqref{eq:equilibrium_constraint}, in addition to the main advantage of MPEC that it does not need to solve the fixed point problem iteratively.

\section{Monte Carlo simulation results}

For comparison, we follow Appendix B of \cite{ursu2023sequential} on the setting of the parameters of $\xi_{ij}$ and $c_{ij}$ in \eqref{eq:mpec_formula}. 
We compare MPEC with their kernel-smoothed frequency estimator with a look-up table, the most frequently used method in empirical work.\footnote{The detailed construction is described in Appendix.} 
We use the same ad hoc table with \cite{ursu2023sequential} for which the grid fineness is 0.001.
We construct 50 simulation data for 1,000 consumers who make search and purchase decisions in a sequential search manner with four brands and an outside option (with mean utility normalized to zero). The utility function only consists of brand intercepts, denoted as $(\beta_1,\beta_2,\beta_3,\beta_4)=(1.0, 0.7. 0.5, 0.3)$. 
The log of search cost $\log c=-3.0$. We use $D=100$ draws of the error terms.
\textcolor{blue}{For the kernel-smoothed frequency simulator, we use the
scaling vector XXX. All estimations start from a vector of zeros. } Our replication Julia code is available on the authors' github.

\begin{table}[!htbp]
  \begin{center}
      \caption{MPEC vs benchmark \textcolor{blue}{[TBA]}}
      \label{tb:results_MPEC_1_bias_rmse} 
      \subfloat[scale $\sigma=20$]{\input{figuretable/target_data_bias_rmse}}
      \subfloat[scale ]{\input{figuretable/target_data_bias_rmse}}
  \end{center}
  \footnotesize
  Note: \textcolor{blue}{We write Julia code for both estimations for fair comparison. The benchmark results correspond with Column (4) in Table B1: Monte Carlo Simulation Results of \cite{ursu2023sequential}.}
\end{table} 

Table \ref{tb:results_MPEC_1_bias_rmse} reports the bias and root-mean-squared-error (RMSE) of estimated coefficients across the 50 data simulations.
\textcolor{blue}{[TBA] It shows that our MPEC estimator achieves better performance in terms of bias and RMSE than the benchmark even without any ad hoc imposed assumption in a look-up table. 
However, the computational time is longer than the benchmark.}
\begin{itemize}
    \item More MPEC advantages over benchmark.
\end{itemize}

\begin{table}[!htbp]
  \begin{center}
      \caption{Summary of results\textcolor{blue}{[TBA]}}
      \begin{tabular}{lcccc} \hline
   Approach &  Speed & Accuracy & Sample size & Tuning\\ 
   \hline
   Look-up table &  Good & bad & small & construction of table \\ 
   Contraction mapping & bad & good & small & Tolerance \\ 
   Newton & bad & good & small & Tolerance \\ 
   MPEC & good & good & large & None \\ 
   \hline
 \end{tabular}
 \label{tb:results} 
  \end{center}
  \footnotesize
  Note: 
\end{table} 



\section{Conclusion}
The optimal sequential search model based on \cite{weitzman1979optimal} has been widely used in empirical studies and a set of empirical approaches is examined by \cite{ursu2023sequential}. 
Some caution, however, is needed in order to address the issue of estimation and approximation accuracy.
In addition, the most widely used approach needs ad hoc look-up table which is unknown to researchers.
We do not know how this ad hoc component would affect the estimates
in finite samples. 
We propose an MPEC estimator that avoids approximation and estimation of equilibrium constraints.
Of course, the cost is that it is more computationally demanding.
However, this is not a big concern now, given the computing power
of recent computers.

\bibliographystyle{aer}
\bibliography{sequential_search}

\newpage
\appendix
\section{Appendix (for online publication)}

\subsection{Crude estimator}

Define
\begin{align}
    v_{i,1h} &= z_{ih} - \max_{k \in \mathcal{J}\setminus \{1,\cdots,h\}} z_{ik} \label{v1}\\
    v_{i,2h} &=  z_{ih} - \max_{k = 1}^{h-1} u_{ik} \label{v2} \\
    v_{i,3} &= \max_{h \in S_i \cup \{0\}} u_{ih} - \max_{l \in \bar{S}_i} z_{il} \label{v3}\\
    v_{i,4} &= u_{iy_i} - \max_{h \in S_i \cup \{0\}} u_{ih}  \label{v4}
\end{align}

\begin{itemize}
    \item[1] Take $d = (1, \cdots, D)$ sets of draws of $\mu_{ij}$ and $\epsilon_{ij}$ (each set of draws contains one draw of $\mu_{ij}$ and one draw of $\epsilon_{ij}$) for each consumer-product combination, i.e., $D\times J \times N$ sets of draws.
    \item[2] For a given guess of parameters $\bm{\theta}$, compute $u^d_{ij}$ and $z^d_{ij}$ for each set of draws $d$ and each consumer-product combination.
    \item[3] Calculate the expressions in equations \eqref{v1} to \eqref{v4} for each set of draws $d$ and each consumer. Compute the likelihood contribution for each consumer and draw:
    \begin{align*}
        L_i^d = \left[\prod_{h \in S_i} \bm{1}\{v^d_{i,1h} \geq 0\} \right] \times \left[\prod_{h \in S_i} \bm{1}\{v^d_{i,2h} \geq 0\} \right] \times  \bm{1}\{v^d_{i,3} \geq 0\}  \times  \bm{1}\{v^d_{i,4} \geq 0\}
    \end{align*}
    \item[4] Compute $L_i = \frac{1}{D}\sum_{d = 1}^D L_i^d$ for each consumer.
    \item[5] Compute $\log L = \sum_{i = 1}^N \log(L_i)$
\end{itemize}

\begin{align*}
    \max_{\theta}& \sum_{i\in \mathcal{N}} \log L_{i}(\theta,(z_{ij})_{j\in \mathcal{J}},(u_{ij})_{j\in \mathcal{J}})\nonumber\\
    \text{s.t.}\quad u_{i j} & =\xi_{i j}+\mu_{i j}+\varepsilon_{i j}\label{eq:mpec_formula}\\
    z_{i j}&=\xi_{i j}+\mu_{i j}+m\left(c_{i j}\right) \nonumber\\
    c_{i j}&=\phi(m)+m \times[\Phi(m)-1] \nonumber
\end{align*}

\subsection{Kernel estimator}
To overcome drawbacks of the crude estimator, the kernel estimator uses a smooth kernel function to obtain the log-likelihood. Specifically, we use a multivariate scaled logistic cdf as the kernel function, which leads to the following the consumer-draw-specific likelihood contribution:
\begin{align*}
    L_i^d = \frac{1}{1 + \sum_{k=1}^2 \sum_{h \in S_i} \exp (- \rho_k v^d_{i,kh}) +  + \sum_{k=1}^2 \exp (- \rho_k v^d_{i,k})},
\end{align*}
where $\rho_k$ is a scaling parameter for each condition, which needs to be chosen by the researchers. The estimation procedure to obtain $v_k$ is the same as the crude estimator.




\end{document}
